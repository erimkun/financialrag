import pdfplumber
from pathlib import Path
import json
from PIL import Image
import io

# $ 1.1 Metin ve 1.2 Tablo Ã‡Ä±karÄ±mÄ± (Context7 best practice: pdfplumber ile)

def extract_text_and_tables(pdf_path):
    text_data = []
    tables_data = []

    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages):
            # Metin Ã§Ä±karÄ±mÄ±
            text = page.extract_text()
            text_data.append({
                "sayfa": i + 1,
                "paragraflar": text.split('\n') if text else []
            })
            
            # Tablo Ã§Ä±karÄ±mÄ± (pdfplumber ile)
            tables = page.extract_tables()
            for j, table in enumerate(tables):
                if table:
                    tables_data.append({
                        "sayfa": i + 1,
                        "tablo_id": j + 1,
                        "data": {"rows": table}
                    })

    return text_data, tables_data

# $ 1.3 ve 1.4 GÃ¶rsel ve BaÅŸlÄ±k Ã‡Ä±karÄ±mÄ± (Context7 best practice: pdfplumber ile Windows uyumlu)
def extract_graphics(pdf_path, output_dir):
    graphics = []
    
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            # SayfanÄ±n tam gÃ¶rselini kaydet (pdfplumber ile)
            page_img_path = output_dir / f"page{page_num + 1}_full.png"
            
            # pdfplumber ile sayfa gÃ¶rselini al
            try:
                page_img = page.to_image(resolution=150)
                page_img.save(page_img_path)
            except Exception as e:
                print(f"Sayfa {page_num + 1} gÃ¶rsel kaydÄ± hatasÄ±: {e}")
                # Alternatif: boÅŸ gÃ¶rsel oluÅŸtur
                blank_img = Image.new('RGB', (800, 600), color='white')
                blank_img.save(page_img_path)
            
            # Sayfa metnini al
            page_text = page.extract_text() or ""
            text_lines = [line.strip() for line in page_text.split('\n') if line.strip()]
            
            # Basit baÅŸlÄ±k tespiti: kÄ±sa, bÃ¼yÃ¼k harfle baÅŸlayan satÄ±rlar
            potential_titles = []
            for line in text_lines:
                if (len(line) < 100 and 
                    len(line) > 10 and 
                    line[0].isupper() and
                    not line.endswith('.') and
                    not line.startswith('â€¢') and
                    not line.isdigit()):
                    potential_titles.append(line)
            
            # Her sayfa iÃ§in bir gÃ¶rsel objesi oluÅŸtur
            title = potential_titles[0] if potential_titles else f"Sayfa {page_num + 1}"
            
            graphics.append({
                "sayfa": page_num + 1,
                "baÅŸlÄ±k": title,
                "gÃ¶rsel_path": str(page_img_path),
                "Ã§Ä±karÄ±lan_veri": None
            })
    
    return graphics

# $ 1.5 Sayfa BazlÄ± JSON Ã‡Ä±ktÄ±

def build_page_objects(texts, tables, graphics):
    page_objs = {}
    
    # Metin verilerini ekle
    for t in texts:
        page_objs[t["sayfa"]] = {
            "sayfa": t["sayfa"],
            "paragraflar": t["paragraflar"],
            "tablolar": [],
            "grafikler": []
        }
    
    # Tablo verilerini ekle
    for tab in tables:
        if tab["sayfa"] in page_objs:
            page_objs[tab["sayfa"]]["tablolar"].append(tab["data"])
    
    # GÃ¶rsel verilerini ekle
    for g in graphics:
        if g["sayfa"] in page_objs:
            page_objs[g["sayfa"]]["grafikler"].append({
                "baÅŸlÄ±k": g["baÅŸlÄ±k"],
                "gÃ¶rsel_path": g["gÃ¶rsel_path"],
                "Ã§Ä±karÄ±lan_veri": g["Ã§Ä±karÄ±lan_veri"]
            })
    
    return list(page_objs.values())

if __name__ == "__main__":
    pdf_path = "2025_07_16_Haziran AyÄ± BÃ¼tce Dengesi.pdf"
    output_dir = Path("extracted_images")
    output_dir.mkdir(exist_ok=True)

    print("ğŸ“„ Metin ve tablo Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor...")
    metinler, tablolar = extract_text_and_tables(pdf_path)
    print(f"âœ… Metin sayfalarÄ±: {len(metinler)}, Tablolar: {len(tablolar)}")
    
    print("ğŸ–¼ï¸ GÃ¶rsel Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor...")
    grafikler = extract_graphics(pdf_path, output_dir)
    print(f"âœ… GÃ¶rseller: {len(grafikler)}")
    
    print("ğŸ“ JSON Ã§Ä±ktÄ±sÄ± oluÅŸturuluyor...")
    sayfa_objeleri = build_page_objects(metinler, tablolar, grafikler)

    with open("extracted_data.json", "w", encoding="utf-8") as f:
        json.dump(sayfa_objeleri, f, ensure_ascii=False, indent=2)

    print("âœ… Ã‡Ä±ktÄ±: extracted_data.json")
    print("âœ… GÃ¶rseller: extracted_images/ klasÃ¶rÃ¼nde")
    print(f"ğŸ“Š Toplam {len(sayfa_objeleri)} sayfa iÅŸlendi")
    
    # Ã–zet bilgileri
    total_paragraphs = sum(len(page.get("paragraflar", [])) for page in sayfa_objeleri)
    total_tables = sum(len(page.get("tablolar", [])) for page in sayfa_objeleri)
    total_graphics = sum(len(page.get("grafikler", [])) for page in sayfa_objeleri)
    
    print(f"ğŸ“ˆ Ã–zet: {total_paragraphs} paragraf, {total_tables} tablo, {total_graphics} gÃ¶rsel") 